version: "3.8"

# YAML Extension for Kafka Controllers (base configuration)
x-kafka-controller-base: &kafka-controller-base
  image: apache/kafka:3.8.0
  environment: &kafka-controller-env
    KAFKA_PROCESS_ROLES: controller
    KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT
    KAFKA_LOG_DIRS: /var/lib/kafka/data
    KAFKA_CONTROLLER_QUORUM_VOTERS: 0@kafka-controller-0:9093,1@kafka-controller-1:9093,2@kafka-controller-2:9093
  deploy:
    restart_policy:
      condition: any
    placement:
        constraints: [node.platform.os == linux]

# YAML Extension for Kafka Brokers (base configuration)
x-kafka-broker-base: &kafka-broker-base
  image: apache/kafka:3.8.0
  environment: &kafka-broker-env
    KAFKA_PROCESS_ROLES: broker
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
    KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
    KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    KAFKA_CONTROLLER_QUORUM_VOTERS: 0@kafka-controller-0:9093,1@kafka-controller-1:9093,2@kafka-controller-2:9093
    KAFKA_LOG_DIRS: /var/lib/kafka/data
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
    KAFKA_DEFAULT_REPLICATION_FACTOR: 3
    KAFKA_LOG_RETENTION_MS: 604800000
    KAFKA_LOG_RETENTION_BYTES: 1073741824
  deploy:
    restart_policy:
      condition: any
    placement:
        constraints: [node.platform.os == linux]

services:
  # Controllers
  kafka-controller-0:
    <<: *kafka-controller-base
    hostname: kafka-controller-0
    environment:
      <<: *kafka-controller-env
      KAFKA_NODE_ID: 0
      KAFKA_LISTENERS: CONTROLLER://kafka-controller-0:9093
    volumes:
      - kafka_controller_data_0:/var/lib/kafka/data
    networks:
      - poc_net

  kafka-controller-1:
    <<: *kafka-controller-base
    hostname: kafka-controller-1
    environment:
      <<: *kafka-controller-env
      KAFKA_NODE_ID: 1
      KAFKA_LISTENERS: CONTROLLER://kafka-controller-1:9093
    volumes:
      - kafka_controller_data_1:/var/lib/kafka/data
    networks:
      - poc_net

  kafka-controller-2:
    <<: *kafka-controller-base
    hostname: kafka-controller-2
    environment:
      <<: *kafka-controller-env
      KAFKA_NODE_ID: 2
      KAFKA_LISTENERS: CONTROLLER://kafka-controller-2:9093
    volumes:
      - kafka_controller_data_2:/var/lib/kafka/data
    networks:
      - poc_net

  # Brokers
  kafka-broker-0:
    <<: *kafka-broker-base
    # hostname: kafka-broker-0
    ports:
      - "9093:9092"
    environment:
      <<: *kafka-broker-env
      KAFKA_NODE_ID: 4
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-0:9092
    volumes:
      - kafka_data_0:/var/lib/kafka/data
      # - ./Certificates:/etc/kafka/secrets
    logging:
      driver: gelf
      options:
        gelf-address: "tcp://10.101.102.84:5044"
        tag: "kafka-broker-0"
    networks:
      - poc_net

  kafka-broker-1:
    <<: *kafka-broker-base
    # hostname: kafka-broker-1
    ports:
      - "9094:9092"
    environment:
      <<: *kafka-broker-env
      KAFKA_NODE_ID: 5
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-1:9092
    volumes:
      - kafka_data_1:/var/lib/kafka/data
      # - ./Certificates:/etc/kafka/secrets
    logging:
      driver: gelf
      options:
        gelf-address: "tcp://10.101.102.84:5044"
        tag: "kafka-broker-1"
    networks:
      - poc_net

  kafka-broker-2:
    <<: *kafka-broker-base
    # hostname: kafka-broker-2
    ports:
      - "9095:9092"
    environment:
      <<: *kafka-broker-env
      KAFKA_NODE_ID: 6
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-2:9092
    volumes:
      - kafka_data_2:/var/lib/kafka/data
      # - ./Certificates:/etc/kafka/secrets
    logging:
      driver: gelf
      options:
        gelf-address: "tcp://10.101.102.84:5044"
        tag: "kafka-broker-2"
    networks:
      - poc_net

  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.8.0
    hostname: kafka-exporter
    ports:
      - "9308:9308"
    command:
      - "--kafka.server=kafka-broker-0:9092"
      - "--kafka.server=kafka-broker-1:9092"
      - "--kafka.server=kafka-broker-2:9092"
    deploy:
      restart_policy:
        condition: on-failure
      replicas: 1  # Replicated for load balancing
      placement:
        constraints: [node.platform.os == linux]
    networks:
      - poc_net

  data-generation:
    image: dip.ad.atsonline.de:5000/cloud_evaluation/data-generation:latest
    hostname: data-generation
    ports:
      - "5247:5247"
    deploy:
      restart_policy:
        condition: on-failure
      replicas: 1
      placement:
        constraints: [node.platform.os == linux]
    networks:
      - poc_net

  producer-vds:
    image: vds-sample-server:windows
    hostname: producer-vds
    ports:
      - "50000:50000"
      - "60000:60000"
    environment:
      - Port_IPv1=50000
      - Port_SecurIP=60000
      - Kafka__Use=true
      - Kafka__Brokers=kafka-broker-0:9092,kafka-broker-1:9092,kafka-broker-2:9092
      - Kafka__Topic=vds-data
    logging:
      driver: gelf
      options:
        gelf-address: "tcp://10.101.102.84:5044"
        tag: "producer-vds"
    deploy:
      restart_policy:
        condition: on-failure
      replicas: 1
      placement:
        constraints: [node.platform.os == windows]
    networks:
      - poc_net

  consumer-vds:
    image: dip.ad.atsonline.de:5000/cloud_evaluation/consumer:latest
    hostname: consumer-vds
    ports:
      - "5121:5121"
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - Kafka__Brokers=kafka-broker-0:9092,kafka-broker-1:9092,kafka-broker-2:9092
      - Kafka__Consumer_Group=vds-group
      - Kafka__Create_Topics__0=vds-data
      - Kafka__Subscribe_Topics__0=vds-data
      - MongoDB__ConnectionStrings="mongodb://mongo0:27017,mongo1:27018,mongo2:27019/?replicaSet=rs0"
    logging:
      driver: gelf
      options:
        gelf-address: "tcp://10.101.102.84:5044"
        tag: "consumer-vds"
    deploy:
      restart_policy:
        condition: on-failure
      replicas: 1
      placement:
        constraints: [node.platform.os == linux]
    networks:
      - poc_net

  dashboard:
    image: dip.ad.atsonline.de:5000/cloud_evaluation/dashboard:v1
    hostname: webapi
    ports:
      - "5185:5185"
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ApiSettings__BaseUrl=http://webapi:5046/
      - ExternalUrls__GrafanaUrl=http://grafana:3000
      - ExternalUrls__KibanaUrl=http://kibana:8082
      - ExternalUrls__PortainerUrl=vds-http://portainer:9000
      - Keycloak__Authority=http://keycloak:8083/realms/GMS
      - Keycloak__ClientId=dashboard
      - Keycloak__ClientSecret=PwMaRz1sccnHZIq4CD4yOqWuhLIl5wlA
    deploy:
      restart_policy:
        condition: on-failure
      replicas: 3
      placement:
        constraints: [node.platform.os == linux]
    networks:
      - poc_net

  webapi:
    image: dip.ad.atsonline.de:5000/cloud_evaluation/webapi:latest
    hostname: webapi
    ports:
      - "5046:5046"
    environment:
      - MongoDbSettings__ConnectionString=mongodb://mongo0:27017,mongo1:27018,mongo2:27019/?replicaSet=rs0
      - MongoDbSettings__DatabaseName=KafkaData
      - MongoDbSettings__CollectionName=KafkaEntries
      - MongoDbSettings__CompanyId=vds-data
    deploy:
      restart_policy:
        condition: on-failure
      replicas: 1
      placement:
        constraints: [node.platform.os == linux]
    networks:
      - poc_net

  prometheus:
    image: prom/prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus_conf:/etc/prometheus
    deploy:
      restart_policy:
        condition: on-failure
      replicas: 1
      placement:
        constraints: [node.platform.os == linux]
    networks:
      - poc_net

  grafana:
    image: grafana/grafana:11.5.2
    hostname: grafana
    ports:
      - "3000:3000"
    environment:
    - GF_AUTH_GENERIC_OAUTH_NAME=OAuth
    - GF_AUTH_BASIC_ENABLED=true
    - GF_AUTH_GENERIC_OAUTH_ENABLED=true
    - GF_AUTH_OAUTH_ALLOW_INSECURE_EMAIL=true
    - GF_AUTH_GENERIC_OAUTH_CLIENT_ID=grafana
    - GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET=rDxobnfffqZxrix8RQP2YVSLpo1eQrjs
    - GF_AUTH_GENERIC_OAUTH_SCOPES="openid profile email"
    - GF_AUTH_GENERIC_OAUTH_AUTH_URL=http://10.101.102.84:8083/realms/GMS/protocol/openid-connect/auth
    - GF_AUTH_GENERIC_OAUTH_TOKEN_URL=http://keycloak:8080/realms/GMS/protocol/openid-connect/token
    - GF_AUTH_GENERIC_OAUTH_API_URL=http:///keycloak:8080/realms/GMS/protocol/openid-connect/userinfo
    - GF_AUTH_GENERIC_OAUTH_SIGNOUT_REDIRECT_URL=http://10.101.102.84:8083/realms/GMS/protocol/openid-connect/logout?post_logout_redirect_uri=http://10.101.102.84:3000/login/generic_oauth/
    - GF_AUTH_GENERIC_OAUTH_TLS_SKIP_VERIFY_INSECURE=true
    - GF_SERVER_ROOT_URL=http://10.101.102.84:3000
    - GF_SERVER_DOMAIN=10.101.102.84
    - GF_AUTH_DISABLE_SIGNOUT_MENU=false
    - GF_AUTH_OAUTH_AUTO_LOGIN=false
    - GF_SECURITY_COOKIE_SECURE=false
    - GF_AUTH_GENERIC_OAUTH_EMAIL_ATTRIBUTE_NAME=email
    - GF_AUTH_GENERIC_OAUTH_ALLOW_SIGN_UP=true
    - GF_AUTH_OAUTH_SKIP_ORG_ROLE_UPDATE_SYNC=false
    - GF_AUTH_SKIP_ORG_ROLE_SYNC=false
    - GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_STRICT=true
    - GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_PATH=contains(role[*], 'admin') && 'GrafanaAdmin' || contains(role[*], 'user') && 'Viewer' 
    - GF_AUTH_DISABLE_LOGIN_FORM=true
    volumes:
      - grafana_data:/var/lib/grafana
    deploy:
      restart_policy:
        condition: on-failure
      replicas: 1
      placement:
        constraints: [node.platform.os == linux]
    networks:
      - poc_net

  # akhq:
  #   image: tchiotludo/akhq
  #   hostname: akhq
  #   ports:
  #     - "8080:8080"
  #   environment:
  #     AKHQ_CONFIGURATION: |
  #       akhq:
  #         connections:
  #           kafka:
  #             properties:
  #               bootstrap.servers: "kafka-broker-0:9092,kafka-broker-1:9092,kafka-broker-2:9092"
  #   deploy:
  #     restart_policy:
  #       condition: on-failure
  #     replicas: 1
  #   networks:
  #     - poc_net

  mongo0:
    image: mongo:8.0.4
    hostname: mongo0
    command: ["--replSet", "rs0", "--bind_ip_all", "--port", "27017"]
    healthcheck:
      test:
        - CMD-SHELL
        - "echo \"try { rs.status() } catch (err) { rs.initiate({_id:'rs0',members:[{_id:0,host:'mongo0:27017',priority:2},{_id:1,host:'mongo1:27018',priority:1},{_id:2,host:'mongo2:27019',priority:0.5}]}) }\" | mongosh --port 27017 --quiet"
      interval: 5s
      timeout: 30s
      retries: 30
    ports:
      - "27017:27017"
    volumes:
      - mongo0_data:/data/db
    logging:
      driver: gelf
      options:
        gelf-address: "tcp://10.101.102.84:5044"
        tag: "mongo0"
    networks:
      - poc_net
    deploy:
      restart_policy:
        condition: on-failure
      placement:
          constraints: [node.platform.os == linux]

  mongo1:
    image: mongo:8.0.4
    hostname: mongo1
    command: ["--replSet", "rs0", "--bind_ip_all", "--port", "27018"]
    ports:
      - "27018:27018"
    volumes:
      - mongo1_data:/data/db
    logging:
      driver: gelf
      options:
        gelf-address: "tcp://10.101.102.84:5044"
        tag: "mongo1"
    deploy:
      restart_policy:
        condition: on-failure
      placement:
          constraints: [node.platform.os == linux]
    networks:
      - poc_net

  mongo2:
    image: mongo:8.0.4
    hostname: mongo2
    command: ["--replSet", "rs0", "--bind_ip_all", "--port", "27019"]
    ports:
      - "27019:27019"
    volumes:
      - mongo2_data:/data/db
    logging:
      driver: gelf
      options:
        gelf-address: "tcp://10.101.102.84:5044"
        tag: "mongo2"
    deploy:
      restart_policy:
        condition: on-failure
      placement:
          constraints: [node.platform.os == linux]
    networks:
      - poc_net

  mongo-express:
    image: mongo-express:latest
    hostname: mongo-express
    ports:
      - "8081:8081"
    environment:
      - ME_CONFIG_MONGODB_URL=mongodb://mongo0:27017,mongo1:27018,mongo2:27019/?replicaSet=rs0
    deploy:
      restart_policy:
        condition: on-failure
      placement:
          constraints: [node.platform.os == linux]
    networks:
      - poc_net

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.1
    hostname: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elastic_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    deploy:
      restart_policy:
        condition: on-failure
      placement:
          constraints: [node.platform.os == linux]
    networks:
      - poc_net

  logstash:
    image: docker.elastic.co/logstash/logstash:8.15.1
    # hostname: logstash
    volumes:
      - logstash_conf:/usr/share/logstash/pipeline/
    ports:
      - "5044:5044"
    networks:
      - poc_net
    deploy:
      mode: replicated
      restart_policy:
        condition: on-failure
      replicas: 1
      placement:
        constraints: [node.role == manager]

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.1
    hostname: kibana
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=admin
      - ELASTICSEARCH_PASSWORD=pass
    ports:
      - "8082:5601"
    volumes:
      - kibana_data:/usr/share/kibana/data
    networks:
      - poc_net
    deploy:
      mode: replicated
      restart_policy:
        condition: on-failure
      replicas: 1
      placement:
        constraints: [node.platform.os == linux]

  keycloak:
    image: quay.io/keycloak/keycloak:26.1.1
    hostname: keycloak
    command: start-dev
    environment:
      - KEYCLOAK_ADMIN=admin
      - KEYCLOAK_ADMIN_PASSWORD=pass
      - KC_PROXY=edge
    ports:
      - "8083:8080"
    volumes:
      - keycloak_data:/opt/keycloak/data
    networks:
      - poc_net
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints: [node.platform.os == linux]

  # Portainer for Docker management
  portainer-agent:
    image: portainer/agent:lts
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - poc_net
    deploy:
      mode: global
      placement:
        constraints: [node.platform.os == linux]

  portainer:
    image: portainer/portainer-ce:lts
    command: -H tcp://tasks.portainer-agent:9001 --tlsskipverify
    ports:
      - "9000:9000"
    volumes:
      - portainer_data:/data
    networks:
      - poc_net
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]

volumes:
  kafka_controller_data_0:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/kafka/"
  kafka_controller_data_1:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/kafka/"
  kafka_controller_data_2:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/kafka/"
  kafka_data_0:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/kafka/"
  kafka_data_1:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/kafka/"
  kafka_data_2:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/kafka/"
  mongo0_data:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/mongo/"
  mongo1_data:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/mongo/"
  mongo2_data:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/mongo/"
  grafana_data:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/grafana/"
  elastic_data:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/elastic/"
  kibana_data:
    driver: local
    # driver_opts:
    #   type: "cifs"
    #   o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
    #   device: "//10.101.102.100/GMS/poc/kibana/"
  portainer_data:
    driver: local
  keycloak_data:
    driver: local
    driver_opts:
      type: "cifs"
      o: "username=GMS-User,password=ATS1g2m3s!,file_mode=0777,dir_mode=0777"
      device: "//10.101.102.100/GMS/poc/keycloak/"
  prometheus_conf:
    driver: local
    driver_opts:
      type: "cifs"
      o: "username=GMS-User,password=ATS1g2m3s!"
      device: "//10.101.102.100/GMS/poc/prometheus/"
  logstash_conf:
    driver: local
    driver_opts:
      type: "cifs"
      o: "username=GMS-User,password=ATS1g2m3s!"
      device: "//10.101.102.100/GMS/poc/logstash/"

networks:
  poc_net:
    driver: overlay
    attachable: true
